{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROTAC-STAN Demo\n",
    "- This is a code demo of PROTAC-STAN for PROTAC degradation prediction. It takes about 5 minutes to run the whole pipeline.\n",
    "- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PROTACs/PROTAC-STAN/blob/main/demo.ipynb) (click Runtime → Run all (Ctrl+F9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Setup\n",
    "In this step, we setup the notebook environment and import required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on CoLab\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "    !pip install torch_geometric==2.5.1\n",
    "    !pip install rdkit==2023.9.2\n",
    "    !git clone https://github.com/PROTACs/PROTAC-STAN\n",
    "    %cd PROTAC-STAN\n",
    "else:\n",
    "    print('Not running on CoLab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "import torch\n",
    "\n",
    "import wandb\n",
    "from data_loader import PROTACLoader, collate_fn\n",
    "from model import PROTAC_STAN\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "In this step, we configure the running settings and model settings.\n",
    "\n",
    "[`wandb`](https://wandb.ai/) is the AI developer platform to train and fine-tune your AI models and develop your AI applications with confidence. Here, we set `mode=\"disabled\"` for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'clf': {'class': 2, 'embed': 192, 'hidden': 64},\n",
      "           'desc': 'model parameters',\n",
      "           'protac': {'edge_dim': 3,\n",
      "                      'embed': 64,\n",
      "                      'feature': 146,\n",
      "                      'hidden': 128},\n",
      "           'protein': {'embed': 1280, 'hidden': 128, 'out_dim': 64},\n",
      "           'seed': 21332,\n",
      "           'tan': {'heads': 2, 'in_dims': [1, 1, 1]},\n",
      "           'type': 'PROTAC-STAN-Demo'},\n",
      " 'train': {'batch_size': 4,\n",
      "           'desc': 'train parameters',\n",
      "           'learning_rate': 0.0005,\n",
      "           'num_epochs': 5,\n",
      "           'train_ratio': 0.8}}\n",
      "Running on: cuda\n"
     ]
    }
   ],
   "source": [
    "from main import setup_seed\n",
    "from pprint import pprint\n",
    "\n",
    "cfg = toml.load('config_demo.toml')\n",
    "model_cfg = cfg['model']\n",
    "train_cfg = cfg['train']\n",
    "\n",
    "setup_seed(model_cfg['seed'])\n",
    "\n",
    "wandb.init(\n",
    "    mode=\"disabled\",\n",
    "    project='protac-stan',\n",
    "    config=cfg,\n",
    "    group=f'run_bz{train_cfg[\"batch_size\"]}_lr{train_cfg[\"learning_rate\"]}',\n",
    ")\n",
    "\n",
    "\n",
    "pprint(cfg)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "In this step, we specifiy train/test dataloader. The demo dataset are stored in `data/demo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('data/PROTAC-fine/protac-fine.csv')\n",
    "# df = df.sample(100, random_state=47) # sample 100 for demo\n",
    "# df.to_csv('data/demo/demo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Dataset: \n",
      "Total size:  100\n",
      "Train size:  80\n",
      "Test size:  20\n",
      "Dropped overlapping:\n",
      "Train size:  80\n",
      "Test size:  20\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = PROTACLoader(\n",
    "    root='data/demo', \n",
    "    name='demo',\n",
    "    batch_size=train_cfg['batch_size'], \n",
    "    collate_fn=collate_fn, \n",
    "    train_ratio=train_cfg['train_ratio']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model\n",
    "In this step, we set up our model with configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROTAC_STAN(\n",
      "  (protac_encoder): MolecularEncoder(\n",
      "    (lin): Linear(in_features=146, out_features=64, bias=True)\n",
      "    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1): EdgedGCNConv(\n",
      "    \t(node_lin): Linear(in_features=64, out_features=128, bias=False)\n",
      "    \t(edge_lin): Linear(in_features=3, out_features=128, bias=False)\n",
      "    )\n",
      "    (conv2): EdgedGCNConv(\n",
      "    \t(node_lin): Linear(in_features=128, out_features=64, bias=False)\n",
      "    \t(edge_lin): Linear(in_features=3, out_features=64, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (e3_ligase_encoder): ProteinEncoder(\n",
      "    (adapter): Linear(in_features=1280, out_features=128, bias=True)\n",
      "    (fc): Linear(in_features=128, out_features=64, bias=True)\n",
      "  )\n",
      "  (poi_encoder): ProteinEncoder(\n",
      "    (adapter): Linear(in_features=1280, out_features=128, bias=True)\n",
      "    (fc): Linear(in_features=128, out_features=64, bias=True)\n",
      "  )\n",
      "  (tan): TAN(\n",
      "    (x_net): FCNet(\n",
      "      (fcnet): Sequential(\n",
      "        (0): Dropout(p=0.2, inplace=False)\n",
      "        (1): Linear(in_features=1, out_features=192, bias=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (y_net): FCNet(\n",
      "      (fcnet): Sequential(\n",
      "        (0): Dropout(p=0.2, inplace=False)\n",
      "        (1): Linear(in_features=1, out_features=192, bias=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (z_net): FCNet(\n",
      "      (fcnet): Sequential(\n",
      "        (0): Dropout(p=0.2, inplace=False)\n",
      "        (1): Linear(in_features=1, out_features=192, bias=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (h_net): Linear(in_features=192, out_features=2, bias=True)\n",
      "    (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = PROTAC_STAN(model_cfg)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, train loss: 0.650\n",
      "Best model updated with roc_auc=0.5000!\n",
      "Test Accuracy: 55.00 %\n",
      "Test Loss: 0.6900\n",
      "Test ROC AUC: 0.5000\n",
      "Test F1 Score: 0.0000\n",
      "Epoch: 2/5, train loss: 0.582\n",
      "Best model updated with roc_auc=0.5960!\n",
      "Test Accuracy: 60.00 %\n",
      "Test Loss: 0.6806\n",
      "Test ROC AUC: 0.5960\n",
      "Test F1 Score: 0.5556\n",
      "Epoch: 3/5, train loss: 0.596\n",
      "Best model updated with roc_auc=0.6616!\n",
      "Test Accuracy: 65.00 %\n",
      "Test Loss: 0.6518\n",
      "Test ROC AUC: 0.6616\n",
      "Test F1 Score: 0.6667\n",
      "Epoch: 4/5, train loss: 0.560\n",
      "Best model updated with roc_auc=0.7071!\n",
      "Test Accuracy: 70.00 %\n",
      "Test Loss: 0.6290\n",
      "Test ROC AUC: 0.7071\n",
      "Test F1 Score: 0.7000\n",
      "Epoch: 5/5, train loss: 0.541\n",
      "Test Accuracy: 70.00 %\n",
      "Test Loss: 0.5941\n",
      "Test ROC AUC: 0.6970\n",
      "Test F1 Score: 0.6667\n"
     ]
    }
   ],
   "source": [
    "from main import train, test\n",
    "\n",
    "model = train(\n",
    "    model, train_loader, test_loader, device, \n",
    "    lr=train_cfg['learning_rate'], \n",
    "    num_epochs=train_cfg['num_epochs'], \n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), f'./demo_model_state_dict.pt') # save model state_dict\n",
    "wandb.finish()\n",
    "\n",
    "# Expected Output are as follows:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protacnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
